{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e0347e17-026e-4181-b5eb-b6d0fc4f78d8",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Building a Spam Filter with Naive Bayes\n",
        "Building a spam filter for SMS messages is a practical and useful application of machine learning algorithms that can help users avoid being bombarded with unwanted messages and improve their overall experience.\n",
        "\n",
        "![](https://www.informaticsinc.com/application/files/4515/2718/5763/iStock-122143117.jpg)\n",
        "\n",
        "In this project, we will delve into the practical application of algorithms by building a spam filter for SMS messages. The aim of this project is to train a computer to classify SMS messages as either spam or non-spam with an accuracy greater than 80%. This will be done by:\n",
        "- leveraging human knowledge of how messages are classified\n",
        "- using the information above to estimate the probability of a new message being either spam or non-spam. \n",
        "- having the computer classify messages as either spam or non-spam based on the probability values.\n",
        "\n",
        "To achieve this, we will use the **Multinomial Naive Bayes** algorithm along with a dataset of 5,572 SMS messages that have already been classified by humans. Tiago A. Almeida and José María Gómez Hidalgo compiled the [dataset](https://dq-content.s3.amazonaws.com/433/SMSSpamCollection), which is available for download from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection).\n",
        "\n",
        "> _If you want to learn more about how the data used in this project was collected, you can visit [this page](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition). Additionally, the page also contains papers authored by the creators of the dataset, which you may find useful._\n",
        "\n",
        "> _Due to the nature of spam messages, the dataset contains content that may be offensive to some users._\n",
        "\n",
        "The dataset comprises pre-labelled SMS messages that have been labelled as either spam or non-spam and will be used to train the algorithm. Once the algorithm is trained, it can be used to classify new messages as spam or non-spam.\n",
        "\n",
        "## Importing Libraries\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "665a98b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the default behaviour of plots\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6d1f0129",
      "metadata": {},
      "source": [
        "## Exploring the Dataset\n",
        "---\n",
        "\n",
        "### 1. Downloading the dataset\n",
        "First, we will download the file from the url using the [requests](https://pypi.org/project/requests/) library, then extract the contents into a local folder. To extract these contents, we use the [zipfile](https://docs.python.org/3/library/zipfile.html) library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b5c095fd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "notebook.ipynb    \u001b[1m\u001b[36msmsspamcollection\u001b[m\u001b[m\n"
          ]
        }
      ],
      "source": [
        "# Pull the data from the url\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Extract the contents into a folder locally\n",
        "folder_name = url.split('/')[-1][:-4]\n",
        "z = zipfile.ZipFile(io.BytesIO(response.content))\n",
        "z.extractall(\"./\" + folder_name)\n",
        "\n",
        "# Check if the extraction process was successful\n",
        "! ls"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b596188d",
      "metadata": {},
      "source": [
        "### 2. Checking the file structure\n",
        "Next, we will check how the file contents are structured (by displaying the first five rows of the file). Understanding how the data is structured makes it easier to work with the data in Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b9295a47",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "ham\tOk lar... Joking wif u oni...\n",
            "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
            "ham\tU dun say so early hor... U c already then say...\n",
            "ham\tNah I don't think he goes to usf, he lives around here though\n"
          ]
        }
      ],
      "source": [
        "# Preview from the command line\n",
        "! cd smsspamcollection; head -n 5 SMSSpamCollection; cd ../"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f875e45a",
      "metadata": {},
      "source": [
        "The data lacks a header row, and the columns are separated by tabs. We can account for these structural attributes when reading the data with Pandas.\n",
        "### 3. Exploring with Pandas\n",
        "Finally, we can read the dataset and explore its attributes further:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3fc26ae6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STRUCTURE:\n",
            "The SMS dataset has 5572 rows and 2 columns.\n",
            "\n",
            "COMPLETENESS:\n",
            "The dataset has 0 number of null values. \n",
            "\n",
            "PREVIEW:\n",
            "Printing the first five rows of the dataset...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>SMS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                                SMS\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read-in the data with pandas\n",
        "df = pd.read_csv(\"./smsspamcollection/SMSSpamCollection\", \n",
        "                 sep= \"\\t\", \n",
        "                 header= None, \n",
        "                 names= [\"label\", \"SMS\"]\n",
        "                )\n",
        "                \n",
        "\n",
        "# Explore dataset attributes\n",
        "print(f'STRUCTURE:\\nThe SMS dataset has {df.shape[0]} rows and {df.shape[1]} columns.\\n')\n",
        "print(f'COMPLETENESS:\\nThe dataset has {df.isnull().sum().sum()} number of null values.', '\\n')\n",
        "\n",
        "print('PREVIEW:\\nPrinting the first five rows of the dataset...')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "08a74e01",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SPAM VS HAM (NON-SPAM):\n",
            "Printing the proportion on spam vs ham messages...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proportion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ham</th>\n",
              "      <td>0.865937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>0.134063</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      proportion\n",
              "ham     0.865937\n",
              "spam    0.134063"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the proportion of spam vs ham messages\n",
        "print('SPAM VS HAM (NON-SPAM):\\n\\\n",
        "Printing the proportion on spam vs ham messages...')\n",
        "df.label.value_counts(normalize= True).to_frame(name='proportion')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f3ebd951",
      "metadata": {},
      "source": [
        "Of the total number of SMS messages in the dataset, about 87% are classified as \"ham\" and the remaining 13% are classified as \"spam\". This indicates that the dataset is representative of the actual message distribution in practice, where most of the messages people receive are legitimate messages (\"ham\") rather than unsolicited messages (\"spam\"). \n",
        "\n",
        "Therefore, the dataset can be considered appropriate for training our filter to accurately distinguish between spam and ham messages, which will ultimately result in an effective spam filter for SMS messages.\n",
        "\n",
        "## Creating the Training and Test Datasets\n",
        "---\n",
        "We found that about 87% of the messages in the dataset are ham and 13% are spam. To build a spam filter, it is helpful to first design a test to ensure that the filter works effectively. \n",
        "\n",
        "We will split our dataset into two categories as follows:\n",
        "1. A training set for teaching the computer how to classify messages.\n",
        "2. A test set for evaluating the performance of the spam filter. \n",
        "> _We'll keep **80%** for training and **20%** for testing._ \n",
        "\n",
        "Our aim is to create a spam filter that can classify new messages with an accuracy greater than 80%. To test this, we will compare the results of the algorithm's classification with that of the human classification on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8a6ff95f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The training set has 4458 records.\n",
            "The test set has 1114 records.\n"
          ]
        }
      ],
      "source": [
        "# Randomize entire dataframe\n",
        "randomized_df = df.sample(frac=1, random_state=1)\n",
        "\n",
        "# Create training and test set\n",
        "num_records = randomized_df.shape[0]\n",
        "train_set_size = round(num_records * 0.8)\n",
        "\n",
        "train_set = randomized_df.iloc[:train_set_size].reset_index(drop=True)\n",
        "test_set = randomized_df.iloc[train_set_size:].reset_index(drop=True)\n",
        "\n",
        "# Verify training set as 80% and test set as 20% of dataframe\n",
        "assert train_set.shape[0] == round(0.8 * randomized_df.shape[0])\n",
        "assert test_set.shape[0] == round(0.2 * randomized_df.shape[0])\n",
        "print(f'The training set has {train_set.shape[0]} records.')\n",
        "print(f'The test set has {test_set.shape[0]} records.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "605ba529",
      "metadata": {},
      "source": [
        "In the next step, we will examine the proportion of spam and ham messages in both the training and test sets. We anticipate that these proportions will be similar to the ones found in the complete dataset, where approximately 87% of the messages are ham and the remaining 13% are spam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "099bf24b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating spam vs ham proportions...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_dataset</th>\n",
              "      <th>train_set</th>\n",
              "      <th>test_set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ham</th>\n",
              "      <td>0.87</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>0.13</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      full_dataset  train_set  test_set\n",
              "ham           0.87       0.87      0.87\n",
              "spam          0.13       0.13      0.13"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Calculating spam vs ham proportions...\")\n",
        "\n",
        "pd.concat([df.label.value_counts(normalize=True).round(2),\n",
        "                     train_set.label.value_counts(normalize=True).round(2),\n",
        "                     test_set.label.value_counts(normalize=True).round(2)], \n",
        "                     axis=1, \n",
        "                     keys=['full_dataset', 'train_set', 'test_set']\n",
        "         )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d1551e96",
      "metadata": {},
      "source": [
        "Since the proportions resemble those of the full dataset, our sampling method is deemed representative, and we can proceed.\n",
        "\n",
        "## Cleaning the Dataset\n",
        "---\n",
        "The Naive Bayes algorithm we'll be using for the spam filter is based on the following two equations, where the letter _w_ denotes words in each SMS:\n",
        "\n",
        "$$ P(Spam\\mid w_1, w_2,...,w_n) \\propto P(Spam) \\cdot \\prod\\limits_{i=1}^{n}P(w_i\\mid Spam)$$\n",
        "\n",
        "$$ P(Ham\\mid w_1, w_2,...,w_n) \\propto P(Ham) \\cdot \\prod\\limits_{i=1}^{n}P(w_i\\mid Ham)$$\n",
        "\n",
        "\n",
        "By analyzing these equations, we can see that each word in the message plays an essential role in helping the algorithm to classify messages as spam or ham. As a result, we will treat every word in each SMS as a variable.\n",
        "\n",
        "However, we have to consider the fact that our dataset should be tidy for our purposes. In general, for data to be considered tidy, it must meet three criteria:\n",
        "\n",
        "1. Each column should be a variable. In our case, we will treat every unique word in each SMS as a variable, so we have multiple columns for each SMS.\n",
        "2. Every row should be an observation. In our case, each row will describe an SMS, with the number of times each unique word occurs in it.\n",
        "3. Third, every cell should contain a single value.\n",
        "\n",
        "> _To get a thorough knowledge of data tidiness rules, read [this article](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html)._\n",
        "\n",
        "\n",
        "### 1. Letter Case and Punctuation\n",
        "In addition to treating every word as a variable in our Naive Bayes algorithm, we will also make the algorithm case and punctuation insensitive. This means that the algorithm will not differentiate between uppercase and lowercase letters, and will ignore any punctuation marks in the messages.\n",
        "\n",
        "For example, the words \"FREE\" and \"free\" will be treated as the same word, and the algorithm will not distinguish between them. Similarly, the presence of a punctuation mark such as a period or exclamation mark at the end of a sentence will not affect the classification of the message as spam or ham.\n",
        "\n",
        "By making the algorithm case and punctuation insensitive, we can simplify the classification process and reduce the number of variables that the algorithm needs to consider. This can help improve the accuracy of the classification by reducing the potential for errors caused by case or punctuation differences in similar words or phrases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ab7f1474",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>SMS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>yep  by the pretty sculpture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>yes  princess  are you going to make me moan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>welp apparently he retired</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>havent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                                SMS\n",
              "0   ham                       yep  by the pretty sculpture\n",
              "1   ham      yes  princess  are you going to make me moan \n",
              "2   ham                         welp apparently he retired\n",
              "3   ham                                            havent \n",
              "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set[\"SMS\"] = (train_set.SMS\n",
        "                         .str.replace(\"\\W\", \" \", regex=True)\n",
        "                         .str.lower()\n",
        "                     )\n",
        "                     \n",
        "train_set.head(5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "34f870f2",
      "metadata": {},
      "source": [
        "### 2. Creating the Vocabulary\n",
        "> _The vocabulary represents the list of all of the unique words that occur in all SMS messages of our training set._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c253b452",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Our vocabulary has 7,783 unique words\n"
          ]
        }
      ],
      "source": [
        "# Split each SMS into a python list\n",
        "train_set[\"SMS\"] = train_set[\"SMS\"].str.split()\n",
        "\n",
        "# Append all the words in each list into a vocabulary\n",
        "vocabulary = []\n",
        "train_set[\"SMS\"].apply(lambda x: [vocabulary.append(item) for item in x]);\n",
        "\n",
        "# Only retain the unique words in the vocabulary\n",
        "vocabulary = list(set(vocabulary))\n",
        "\n",
        "# Check the number of unique words in the vocabulary\n",
        "print(\"Our vocabulary has {:,} unique words\".format(len(vocabulary)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f4721421",
      "metadata": {},
      "source": [
        "### 3. The Final Training Set\n",
        "We can create a tidy dataframe by using the words in our vocabulary. This dataframe will have distinct columns for each unique word. Each column will store the number of times the word appears in an SMS message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "457d43a9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wocay</th>\n",
              "      <th>sip</th>\n",
              "      <th>spelling</th>\n",
              "      <th>subscribed</th>\n",
              "      <th>door</th>\n",
              "      <th>nursery</th>\n",
              "      <th>transcribing</th>\n",
              "      <th>itcould</th>\n",
              "      <th>3ss</th>\n",
              "      <th>csh11</th>\n",
              "      <th>...</th>\n",
              "      <th>reserve</th>\n",
              "      <th>financial</th>\n",
              "      <th>senthil</th>\n",
              "      <th>sense</th>\n",
              "      <th>capacity</th>\n",
              "      <th>werethe</th>\n",
              "      <th>sensible</th>\n",
              "      <th>starshine</th>\n",
              "      <th>voda</th>\n",
              "      <th>1172</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 7783 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   wocay  sip  spelling  subscribed  door  nursery  transcribing  itcould  \\\n",
              "0      0    0         0           0     0        0             0        0   \n",
              "1      0    0         0           0     0        0             0        0   \n",
              "2      0    0         0           0     0        0             0        0   \n",
              "3      0    0         0           0     0        0             0        0   \n",
              "4      0    0         0           0     0        0             0        0   \n",
              "\n",
              "   3ss  csh11  ...  reserve  financial  senthil  sense  capacity  werethe  \\\n",
              "0    0      0  ...        0          0        0      0         0        0   \n",
              "1    0      0  ...        0          0        0      0         0        0   \n",
              "2    0      0  ...        0          0        0      0         0        0   \n",
              "3    0      0  ...        0          0        0      0         0        0   \n",
              "4    0      0  ...        0          0        0      0         0        0   \n",
              "\n",
              "   sensible  starshine  voda  1172  \n",
              "0         0          0     0     0  \n",
              "1         0          0     0     0  \n",
              "2         0          0     0     0  \n",
              "3         0          0     0     0  \n",
              "4         0          0     0     0  \n",
              "\n",
              "[5 rows x 7783 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize a dictionary with each vocabulary word as keys and the length of the dataset as values\n",
        "word_count_per_SMS = {word: [0]* train_set.shape[0] for word in vocabulary}\n",
        "\n",
        "# Estimate the number of times each unique word apears in each SMS message\n",
        "for index, words in enumerate(train_set.SMS):\n",
        "    for word in (words):\n",
        "        word_count_per_SMS[word][index] += 1\n",
        "\n",
        "# Covert results into a Pandas dataframe\n",
        "word_count_df = pd.DataFrame(word_count_per_SMS)\n",
        "word_count_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e361152b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>SMS</th>\n",
              "      <th>wocay</th>\n",
              "      <th>sip</th>\n",
              "      <th>spelling</th>\n",
              "      <th>subscribed</th>\n",
              "      <th>door</th>\n",
              "      <th>nursery</th>\n",
              "      <th>transcribing</th>\n",
              "      <th>itcould</th>\n",
              "      <th>...</th>\n",
              "      <th>reserve</th>\n",
              "      <th>financial</th>\n",
              "      <th>senthil</th>\n",
              "      <th>sense</th>\n",
              "      <th>capacity</th>\n",
              "      <th>werethe</th>\n",
              "      <th>sensible</th>\n",
              "      <th>starshine</th>\n",
              "      <th>voda</th>\n",
              "      <th>1172</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>[yep, by, the, pretty, sculpture]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>[welp, apparently, he, retired]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>[havent]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 7785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                                SMS  wocay  sip  \\\n",
              "0   ham                  [yep, by, the, pretty, sculpture]      0    0   \n",
              "1   ham  [yes, princess, are, you, going, to, make, me,...      0    0   \n",
              "2   ham                    [welp, apparently, he, retired]      0    0   \n",
              "3   ham                                           [havent]      0    0   \n",
              "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...      0    0   \n",
              "\n",
              "   spelling  subscribed  door  nursery  transcribing  itcould  ...  reserve  \\\n",
              "0         0           0     0        0             0        0  ...        0   \n",
              "1         0           0     0        0             0        0  ...        0   \n",
              "2         0           0     0        0             0        0  ...        0   \n",
              "3         0           0     0        0             0        0  ...        0   \n",
              "4         0           0     0        0             0        0  ...        0   \n",
              "\n",
              "   financial  senthil  sense  capacity  werethe  sensible  starshine  voda  \\\n",
              "0          0        0      0         0        0         0          0     0   \n",
              "1          0        0      0         0        0         0          0     0   \n",
              "2          0        0      0         0        0         0          0     0   \n",
              "3          0        0      0         0        0         0          0     0   \n",
              "4          0        0      0         0        0         0          0     0   \n",
              "\n",
              "   1172  \n",
              "0     0  \n",
              "1     0  \n",
              "2     0  \n",
              "3     0  \n",
              "4     0  \n",
              "\n",
              "[5 rows x 7785 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Concatenate the training set datframe with the word counts dataframe\n",
        "train_set_clean = pd.concat([train_set, word_count_df], axis=1)\n",
        "train_set_clean.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "111d3fca",
      "metadata": {},
      "source": [
        "## Calculating Constants First\n",
        "---\n",
        "After completing the data cleaning process and obtaining a training dataset, we can now start building the spam filter using the Naive Bayes algorithm. In order to classify new messages, the algorithm requires the probability values of the two equations provided below:\n",
        "\n",
        "$$ P(Spam\\mid w_1, w_2,...,w_n) \\propto P(Spam) \\cdot \\prod\\limits_{i=1}^{n}P(w_i\\mid Spam)$$\n",
        "\n",
        "$$ P(Ham\\mid w_1, w_2,...,w_n) \\propto P(Ham) \\cdot \\prod\\limits_{i=1}^{n}P(w_i\\mid Ham)$$\n",
        "\n",
        "Moreover, in order to calculate _P(w<sub>i</sub>|Spam)_ and _P(w<sub>i</sub>|Ham)_ in the equations above, we need to utilize the following formulas:\n",
        "\n",
        "$$ P(w_i\\mid Spam) = \\frac{N_{(w_i\\mid Spam)} + \\alpha}{N_{spam} + \\alpha \\cdot N_{Vocabulary}} $$\n",
        "\n",
        "$$ P(w_i\\mid Ham) = \\frac{N_{(w_i\\mid Ham)} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}} $$\n",
        "\n",
        "It's important to note that some of the terms in these four equations will have identical values for every new message. Therefore, we can calculate the values of these terms once and avoid re-computing them every time a new message is received. To achieve this, we will use our training dataset to calculate:\n",
        "\n",
        "1. The probability of spam and ham messages in the training set: P(Spam) and P(Ham).\n",
        "\n",
        "2. The total number of words in all spam messages and ham messages: N<sub><i>Spam</i></sub> and N<sub><i>Ham</i></sub>.\n",
        "\n",
        "3. The total number of unique words in all spam messages and ham messages: N<sub><i>Vocabulary</i></sub>.\n",
        "\n",
        "> _For the smoothing constant ($\\alpha$), we will use Laplace smoothing and set $\\alpha$ = 1._\n",
        "\n",
        "Once we have these calculations, we can easily determine the probability of a new message being spam or ham based on its word frequency. This approach will allow the Naive Bayes algorithm to more efficiently and accurately classify new messages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ae53a101",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating a table of constants...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p_spam</th>\n",
              "      <th>p_ham</th>\n",
              "      <th>n_spam</th>\n",
              "      <th>n_ham</th>\n",
              "      <th>n_vocabulary</th>\n",
              "      <th>alpha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>values</th>\n",
              "      <td>0.13459</td>\n",
              "      <td>0.86541</td>\n",
              "      <td>15190</td>\n",
              "      <td>57237</td>\n",
              "      <td>7783</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         p_spam    p_ham  n_spam  n_ham  n_vocabulary  alpha\n",
              "values  0.13459  0.86541   15190  57237          7783      1"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a dictionary to hold the constants\n",
        "constants = {\n",
        "    # Probability of spam\n",
        "    'p_spam': train_set_clean.label.value_counts(normalize=True)['spam'],\n",
        "    # Probability of non spam\n",
        "    'p_ham':  train_set_clean.label.value_counts(normalize=True)['ham'],\n",
        "    # number of words in all spam messages\n",
        "    'n_spam': train_set_clean.groupby('label').sum().sum(axis=1)['spam'],\n",
        "    # number of words in all non spam messages\n",
        "    'n_ham': train_set_clean.groupby('label').sum().sum(axis=1)['ham'],\n",
        "    # number of unique words in vocabulary\n",
        "    'n_vocabulary': len(word_count_per_SMS),\n",
        "    # Laplace smooting constant\n",
        "    'alpha': 1\n",
        "}\n",
        "\n",
        "# Preview the values of the constants\n",
        "print('Creating a table of constants...')\n",
        "pd.DataFrame(constants, index=['values'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4885cece",
      "metadata": {},
      "source": [
        "## Calculating Parameters\n",
        "---\n",
        "Using the constant terms calculated earlier, we can proceed to calculate the parameters for _P(w<sub>i</sub>|Spam)_ and _P(w<sub>i</sub>|Ham)_, which will be the conditional probability values for each word in our vocabulary. To calculate these parameters, we will use the following formulas:\n",
        "\n",
        "$$ P(w_i\\mid Spam) = \\frac{N_{(w_i\\mid Spam)} + \\alpha}{N_{spam} + \\alpha \\cdot N_{Vocabulary}} $$\n",
        "\n",
        "$$ P(w_i\\mid Ham) = \\frac{N_{(w_i\\mid Ham)} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "548cc754",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize a dictionary of spam and ham parameters\n",
        "spam_parameters = {item: 0 for item in vocabulary}\n",
        "ham_parameters = {item: 0 for item in vocabulary}\n",
        "\n",
        "# Isolate spam and ham messages from the training set\n",
        "spam_messages = train_set_clean.loc[train_set_clean['label'] == 'spam']\n",
        "ham_messages = train_set_clean.loc[train_set_clean['label'] == 'ham']\n",
        "\n",
        "# Calculate parameters\n",
        "for word in vocabulary:\n",
        "    p_word_given_spam = ((spam_messages[word].sum() + constants['alpha'])/\n",
        "                         (constants['n_spam'] + constants['alpha']*constants['n_vocabulary'])\n",
        "                        )\n",
        "    \n",
        "    p_word_given_ham  = ((ham_messages[word].sum() + constants['alpha'])/\n",
        "                         (constants['n_ham'] + constants['alpha']*constants['n_vocabulary'])\n",
        "                        )\n",
        "    \n",
        "    spam_parameters[word] = p_word_given_spam\n",
        "    ham_parameters[word] = p_word_given_ham"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b468aaf3",
      "metadata": {},
      "source": [
        "## Common Words in Spam Messages\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "nteract": {
      "version": "0.28.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
